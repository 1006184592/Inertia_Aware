#!/usr/bin/env python3
"""
åŸºçº¿æ¨¡å‹é²æ£’æ€§åˆ†æé€‚é…å™¨
ç›´æ¥ä½¿ç”¨ robustness_analysis_experiment.py ä¸­çš„æ‰€æœ‰å‡½æ•°ï¼Œåªæ›¿æ¢æ¨¡å‹åˆ›å»ºå’Œè®­ç»ƒéƒ¨åˆ†
"""

import os
import sys
import warnings
import torch
import torch.nn as nn
import numpy as np
from pathlib import Path
import time
# æŠ‘åˆ¶è­¦å‘Š
warnings.filterwarnings('ignore', category=FutureWarning, module='statsmodels')
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

# ç¡®ä¿ä¼˜å…ˆä½¿ç”¨ adap_auto/new_hier ä¸‹çš„æ¨¡å—ï¼ˆå¦‚ DataEmbeddingã€adap_auto_xï¼‰
_ex_dir = os.path.dirname(os.path.abspath(__file__))            # .../adap_auto/new_hier/ex-experiment
_new_hier_dir = os.path.dirname(_ex_dir)                        # .../adap_auto/new_hier
if _new_hier_dir not in sys.path:
	sys.path.insert(0, _new_hier_dir)
# æ¸…ç†å¯èƒ½çš„å†²çªç¼“å­˜
for _m in ['DataEmbedding', 'adap_auto']:
	sys.modules.pop(_m, None)

# å¯¼å…¥æ‰€æœ‰é²æ£’æ€§åˆ†æå‡½æ•°
from robustness_analysis_experiment import (
	run_robustness_experiment,
	evaluate_model_robustness,
	load_window_data_directly,
	seed_everything,
	save_results,
	load_baseline_results,
	create_robustness_visualizations,
	split_data_by_season_independent,
	inverse_or_identity
)
# ç¡®ä¿å¯ä»¥å¯¼å…¥åˆ°adap_auto/new_hier/evaluate.py
_current_dir = os.path.dirname(os.path.abspath(__file__))
_parent_dir = os.path.dirname(os.path.dirname(_current_dir))
if _parent_dir not in sys.path:
	sys.path.insert(0, _parent_dir)
from evaluate import MSE, MAPE

def create_baseline_model_adapter(model_name, seq_len, pred_len, enc_in, device):
	"""
	åˆ›å»ºåŸºçº¿æ¨¡å‹çš„é€‚é…å™¨å‡½æ•°
	ç›´æ¥å¯¼å…¥å¹¶ä½¿ç”¨ç°æœ‰çš„æ¨¡å‹ç±»
	"""
	script_dir = os.path.dirname(os.path.abspath(__file__))
	# ä» adap_auto/new_hier/ex-experiment åˆ°é¡¹ç›®æ ¹ç›®å½•éœ€è¦ä¸Š3çº§
	project_root = os.path.dirname(os.path.dirname(os.path.dirname(script_dir)))
	
	# ä¸´æ—¶ä¿å­˜åŸå§‹sys.path
	original_path = sys.path.copy()
	
	if model_name == 'DLinear':
		# æ·»åŠ DLinearè·¯å¾„å¹¶å¯¼å…¥
		dlinear_path = os.path.join(project_root, 'DLinear')
		if dlinear_path not in sys.path:
			sys.path.insert(0, dlinear_path)
		
		try:
			from dlinear_adapted import DLinear  # ä½¿ç”¨é€‚é…ç‰ˆæœ¬
			model = DLinear(
				input_size=seq_len,
				h=1,                     # å•ç‰¹å¾é¢„æµ‹ï¼ˆç›®æ ‡ç‰¹å¾ï¼‰
				c_in=enc_in,             # è¾“å…¥ç‰¹å¾æ•°
				c_out=pred_len,          # é¢„æµ‹æ­¥é•¿
				MovingAvg_window=25,
				dropout=0.05,
				individual=True
			)
		except ImportError as e:
			print(f"æ— æ³•å¯¼å…¥DLinear: {e}")
			raise
				
	elif model_name == 'iTransformer':
		# æ·»åŠ iTransformerè·¯å¾„å¹¶å¯¼å…¥
		itransformer_path = os.path.join(project_root, 'iTransformer')
		
		# æ¸…é™¤å·²åŠ è½½çš„åŒåæ¨¡å—ç¼“å­˜ï¼ˆå…³é”®ï¼‰
		for m in ['DataEmbedding', 'Encoder', 'attention', 'iTransformer', 'FEDformer']:
			sys.modules.pop(m, None)

		# æŠŠç›®æ ‡æ¨¡å‹ç›®å½•æ’åˆ° sys.path æœ€å‰
		sys.path.insert(0, itransformer_path)
		try:
			from iTransformer import iTransformer
			model = iTransformer(
				input_size=seq_len,      # è¾“å…¥åºåˆ—é•¿åº¦
				c_out=pred_len,          # é¢„æµ‹æ­¥é•¿
				h=1,                     # å•ç‰¹å¾é¢„æµ‹
				hidden_size=256,         # éšè—å±‚å¤§å°
				n_heads=8,               # æ³¨æ„åŠ›å¤´æ•°
				d_ff=512,                # å‰é¦ˆç½‘ç»œç»´åº¦
				factor=1,
				dropout=0.1,
				e_layers=2,              # ç¼–ç å™¨å±‚æ•°
				d_layers=1,              # è§£ç å™¨å±‚æ•°
				use_norm=True
			)
		except ImportError as e:
			print(f"æ— æ³•å¯¼å…¥iTransformer: {e}")
			raise
		finally:
			sys.path.pop(0)
				
	elif model_name == 'FEDformer':
		# æ·»åŠ FEDformerè·¯å¾„å¹¶å¯¼å…¥ (æ³¨æ„æ–‡ä»¶å¤¹åæ˜¯FEDfomer)
		fedformer_path = os.path.join(project_root, 'FEDfomer')
		
		# æ¸…é™¤å·²åŠ è½½çš„åŒåæ¨¡å—ç¼“å­˜ï¼ˆå…³é”®ï¼‰
		for m in ['DataEmbedding', 'Encoder', 'attention', 'iTransformer', 'FEDformer', 'seriesDecomp']:
			sys.modules.pop(m, None)

		# æŠŠç›®æ ‡æ¨¡å‹ç›®å½•æ’åˆ° sys.path æœ€å‰
		sys.path.insert(0, fedformer_path)
		try:
			from FEDformer import FEDformer
			model = FEDformer(
				input_size=seq_len,
				version="Fourier",
				modes=64,
				mode_select="ran",
				hidden_size=128,
				dropout=0.05,
				n_head=8,
				conv_hidden_size=32,
				activation="gelu",
				encoder_layers=2,
				decoder_layers=1,
				MovingAvg_window=25,
				c_in=enc_in,
				c_out=pred_len,
				h=1
			)
		except ImportError as e:
			print(f"æ— æ³•å¯¼å…¥FEDformer: {e}")
			raise
		finally:
			sys.path.pop(0)
				
	elif model_name == 'NBEATSx':
		# æ·»åŠ NBEATSxè·¯å¾„å¹¶å¯¼å…¥
		nbeatsx_path = os.path.join(project_root, 'nbeatsx')
		# æ¸…é™¤å·²åŠ è½½æ¨¡å—ç¼“å­˜
		for m in ['NBEATSx']:
			sys.modules.pop(m, None)

		# ä¸´æ—¶æ’å…¥è·¯å¾„
		sys.path.insert(0, nbeatsx_path)
		try:
			from NBEATSx import NBEATSx
			model = NBEATSx(
				seq_len=seq_len,
				pred_len=pred_len,
				enc_in=1,  # NBEATSxåªä½¿ç”¨åŠŸç‡ç‰¹å¾
				c_out=1,
				n_harmonics=2,
				n_polynomials=2,
				stack_types=["identity", "trend", "seasonality"],
				n_blocks=[1, 1, 1],
				mlp_units=[[512, 512], [512, 512], [512, 512]],
				dropout_prob_theta=0.05,
				activation="ReLU",
				shared_weights=False
			)
		except ImportError as e:
			print(f"æ— æ³•å¯¼å…¥NBEATSx: {e}")
			raise
		finally:
			sys.path.pop(0)
	else:
		raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
	
	# æ¢å¤åŸå§‹sys.path
	sys.path = original_path
	
	return model.to(device)

def run_baseline_robustness_experiment(dataset_name, prediction_scale, args, device, model_name):
	"""
	è¿è¡ŒåŸºçº¿æ¨¡å‹çš„é²æ£’æ€§åˆ†æå®éªŒ
	ç›´æ¥å¤ç”¨ robustness_analysis_experiment.py çš„é€»è¾‘ï¼Œåªæ›¿æ¢æ¨¡å‹éƒ¨åˆ†
	"""
	print(f"\nğŸ”¬ å¼€å§‹ {model_name} é²æ£’æ€§åˆ†æå®éªŒ")
	print(f"æ•°æ®é›†: {dataset_name}")
	print(f"é¢„æµ‹å°ºåº¦: {prediction_scale}")
	
	start_time = time.time()
	
	try:
		# 1. æ•°æ®å‡†å¤‡ - ç›´æ¥ä½¿ç”¨ç°æœ‰å‡½æ•°
		print("ğŸ“Š å‡†å¤‡æ•°æ®...")
		model_data = load_window_data_directly(
			dataset_name=dataset_name,
			prediction_scale=prediction_scale,
			seq_length=args.seq_length,
			c_out=None,
			split_ratio=args.split_ratio,
			use_std=False if model_name in ['DLinear', 'NBEATSx'] else True
		)
		
		X_train = model_data['X_train'].to(device)
		y_train = model_data['y_train'].to(device)
		X_test = model_data['X_test'].to(device)
		y_test = model_data['y_test'].to(device)
		train_edge_indices = model_data['train_edge_indices']
		test_edge_indices = model_data['test_edge_indices']
		scaler = model_data['scaler']
		
		print(f"è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}, {y_train.shape}")
		print(f"æµ‹è¯•é›†å½¢çŠ¶: {X_test.shape}, {y_test.shape}")
		print(f"ç‰¹å¾æ•°é‡: {model_data['num_features']}")
		print(f"pred_len: {model_data['pred_length']}")
		
		# 2. æ¨¡å‹åˆå§‹åŒ– - ä½¿ç”¨é€‚é…å™¨åˆ›å»ºåŸºçº¿æ¨¡å‹
		print(f"ğŸ—ï¸ åˆå§‹åŒ– {model_name} æ¨¡å‹...")
		model = create_baseline_model_adapter(
			model_name=model_name,
			seq_len=args.seq_length,
			pred_len=model_data['pred_length'],  # ä¸è¦å†™æ­» 1
			enc_in=model_data['num_features'],
			device=device
		)
		
		# 2.1 è®­ç»ƒå‰å½¢çŠ¶è‡ªæ£€ï¼ˆå°æ‰¹æ¬¡å¹²è·‘ï¼‰
		print("ğŸ§ª å½¢çŠ¶è‡ªæ£€(dry-run)...")
		wrapper = BaselineModelWrapper(model, model_name)
		with torch.no_grad():
			bs = min(16, X_train.shape[0])
			out = wrapper(X_train[:bs])
			print(f"  dry-run output: {tuple(out.shape)}, target: {tuple(y_train[:bs].shape)}")
			if out.shape != y_train[:bs].shape:
				raise ValueError(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶{tuple(out.shape)}ä¸æ ‡ç­¾{tuple(y_train[:bs].shape)}ä¸ä¸€è‡´ï¼Œè¯·æ£€æŸ¥pred_len/è¾“å…¥å¤„ç†ã€‚")
		
		# 3. è®­ç»ƒå¹¶è¯„ä¼°ï¼ˆæ”¯æŒå­£èŠ‚æ¨¡å¼ï¼‰
		if args.seasonal_mode == 'independent':
			print("ğŸŒ¸ ä½¿ç”¨å­£èŠ‚ç‹¬ç«‹æ¨¡å¼...")
			seasonal_data = split_data_by_season_independent({
				'X_train': X_train, 'y_train': y_train,
				'X_test': X_test, 'y_test': y_test,
				'train_edge_indices': train_edge_indices,
				'test_edge_indices': test_edge_indices,
				'scaler': scaler,
			}, device, season_split_ratio=args.season_split_ratio)

			seasonal_results = {}
			for season, data in seasonal_data.items():
				print(f"\nğŸ”¬ è®­ç»ƒ {season} å­£èŠ‚çš„ {model_name} æ¨¡å‹...")
				season_model = create_baseline_model_adapter(
					model_name=model_name,
					seq_len=args.seq_length,
					pred_len=model_data['pred_length'],
					enc_in=model_data['num_features'],
					device=device
				)
				season_model = train_baseline_model_standard(
					season_model,
					data['X_train'], data['y_train'],
					data['X_test'], data['y_test'],
					args, device, model_name
				)
				# è¯„ä¼°
				season_model.eval()
				with torch.no_grad():
					season_wrapper = BaselineModelWrapper(season_model, model_name)
					preds_np = season_wrapper(data['X_test']).cpu().numpy()  # [batch, pred_len]
					y_true_np = data['y_test'].cpu().numpy()               # [batch, pred_len]
					y_true_denorm = inverse_or_identity(y_true_np, scaler, power_feature_idx=0)
					preds_denorm = inverse_or_identity(preds_np, scaler, power_feature_idx=0)
					mse = MSE(y_true_denorm, preds_denorm)
					mape = MAPE(y_true_denorm, preds_denorm)
				seasonal_results[season] = {
					'MSE': mse,
					'MAPE': mape,
					'train_samples': data.get('train_samples', len(data['X_train'])),
					'test_samples': data.get('test_samples', len(data['X_test'])),
					'total_samples': data.get('total_samples', len(data['X_train']) + len(data['X_test']))
				}
				print(f"  {season}: MSE={mse:.4f}, MAPE={mape:.2f}%")

			robustness_results = {
				'seasonal_performance': seasonal_results,
				'seasonal_mode': 'independent'
			}
		else:
			print(f"ï¿½ï¿½ å¼€å§‹è®­ç»ƒ {model_name} æ¨¡å‹...")
			model = train_baseline_model_standard(
				model, X_train, y_train, X_test, y_test, args, device, model_name
			)
			print("ğŸ” å¼€å§‹é²æ£’æ€§è¯„ä¼°...")
			robustness_results = evaluate_model_robustness(
				model=wrapper,
				X_test=X_test,
				y_test=y_test,
				test_edge_indices=test_edge_indices,
				scaler=scaler,
				device=device,
				noise_levels=args.noise_levels,
				missing_ratios=args.missing_ratio,
				dataset_name=dataset_name,
				include_seasonal_in_default=args.include_seasonal_eval
			)
		
		# æ·»åŠ æ¨¡å‹ä¿¡æ¯
		training_time = time.time() - start_time
		robustness_results['training_time'] = training_time
		robustness_results['model_name'] = model_name
		robustness_results['dataset'] = dataset_name
		robustness_results['prediction_scale'] = prediction_scale
		if 'seasonal_mode' not in robustness_results:
			robustness_results['seasonal_mode'] = 'test_split'
		
		return robustness_results
		
	except Exception as e:
		print(f"âŒ {model_name} å®éªŒå¤±è´¥: {str(e)}")
		import traceback
		traceback.print_exc()
		return None

class BaselineModelWrapper:
	"""
	åŸºçº¿æ¨¡å‹åŒ…è£…å™¨ï¼Œä½¿å…¶æ¥å£ä¸ adap_auto å…¼å®¹
	"""
	def __init__(self, model, model_name):
		self.model = model
		self.model_name = model_name
	
	def __call__(self, X, edge_indices=None):
		"""
		ç»Ÿä¸€çš„è°ƒç”¨æ¥å£
		edge_indices å¯¹åŸºçº¿æ¨¡å‹æ— ç”¨ï¼Œå¿½ç•¥
		"""
		if self.model_name == 'NBEATSx':
			# NBEATSx åªéœ€è¦åŠŸç‡ç‰¹å¾ï¼Œä¸”æœŸæœ›ä¸‰ç»´è¾“å…¥ [B, L, 1]
			X_power = X[:, :, 0:1]  # [batch, seq_len, 1]
			output = self.model(X_power)
		else:
			output = self.model(X)
		
		# ç»Ÿä¸€è¾“å‡ºå½¢çŠ¶ä¸º [batch, pred_len]
		if output.ndim == 3 and output.shape[-1] == 1:
			output = output.squeeze(-1)
		# ä¸è¦å°† [batch, pred_len] è¯¯è£æˆ [batch, 1]
		return output
	
	def eval(self):
		return self.model.eval()
	
	def train(self):
		return self.model.train()

def train_baseline_model_standard(model, X_train, y_train, X_test, y_test, args, device, model_name):
	"""
	æ ‡å‡†çš„åŸºçº¿æ¨¡å‹è®­ç»ƒå‡½æ•°
	"""
	from torch.utils.data import DataLoader, TensorDataset
	import time
	
	# å‡†å¤‡æ•°æ®åŠ è½½å™¨
	train_dataset = TensorDataset(X_train, y_train)
	train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)
	
	# ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
	optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
	criterion = nn.MSELoss()
	best_model_state = None
	
	# è®­ç»ƒå¾ªç¯
	best_val_loss = float('inf')
	patience_counter = 0
	
	for epoch in range(args.epochs):
		# è®­ç»ƒé˜¶æ®µ
		model.train()
		train_loss = 0.0
		
		for batch_X, batch_y in train_loader:
			batch_X, batch_y = batch_X.to(device), batch_y.to(device)
			
			optimizer.zero_grad()
			
			# æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´è¾“å…¥
			if model_name == 'NBEATSx':
				batch_X_input = batch_X[:, :, 0:1]  # åªä½¿ç”¨åŠŸç‡ç‰¹å¾ï¼Œä¿æŒ [B, L, 1]
			else:
				batch_X_input = batch_X
			
			outputs = model(batch_X_input)
			
			# ç¡®ä¿è¾“å‡ºç»´åº¦åŒ¹é…
			if len(outputs.shape) > len(batch_y.shape):
				outputs = outputs.squeeze(-1)
			
			loss = criterion(outputs, batch_y)
			
			# L1æ­£åˆ™åŒ–
			if hasattr(args, 'l1_lambda') and args.l1_lambda > 0:
				l1_reg = torch.tensor(0.).to(device)
				for param in model.parameters():
					l1_reg += torch.norm(param, 1)
				loss += args.l1_lambda * l1_reg
			
			loss.backward()
			optimizer.step()
			
			train_loss += loss.item()
		
		# éªŒè¯é˜¶æ®µ
		model.eval()
		val_loss = 0.0
		
		with torch.no_grad():
			if model_name == 'NBEATSx':
				X_test_input = X_test[:, :, 0:1]
			else:
				X_test_input = X_test
				
			prediction = model(X_test_input)
			if len(prediction.shape) > len(y_test.shape):
				prediction = prediction.squeeze(-1)
			val_loss = criterion(prediction, y_test).item()
		
		train_loss /= len(train_loader)
		
		if epoch % 5 == 0:
			print(f"Epoch {epoch+1}/{args.epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}")
		
		# æ—©åœæ£€æŸ¥
		if val_loss < best_val_loss:
			best_val_loss = val_loss
			patience_counter = 0
			best_model_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}
		else:
			patience_counter += 1
			if patience_counter >= args.patience:
				print(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
				break
	
	# åŠ è½½æœ€ä½³æ¨¡å‹
	if best_model_state is not None:
		model.load_state_dict(best_model_state)
	else:
		print("âš ï¸ æœªæ•è·åˆ°æ›´ä¼˜æ¨¡å‹å‚æ•°ï¼Œä½¿ç”¨æœ€åä¸€è½®å‚æ•°")
	print(f"âœ… {model_name} æ¨¡å‹è®­ç»ƒå®Œæˆ")
	
	return model

def main():
	import argparse
	import time
	from pathlib import Path
	
	parser = argparse.ArgumentParser(description='Baseline Model Robustness Analysis')
	
	# æ•°æ®é›†ç›¸å…³å‚æ•°
	parser.add_argument('--dataset', type=str, default='fujian', choices=['fujian', 'DSWE'], 
						help='Dataset name')
	parser.add_argument('--prediction_scale', type=str, default='6-0_1', 
						help='Prediction scale (e.g., 6-0_1, 24-1, etc.)')
	parser.add_argument('--model', type=str, required=False,
						choices=['DLinear', 'iTransformer', 'FEDformer', 'NBEATSx'],
						help='Baseline model to test')
	parser.add_argument('--models', nargs='+', type=str, required=False,
						choices=['DLinear', 'iTransformer', 'FEDformer', 'NBEATSx'],
						help='Run multiple baseline models in sequence')
	
	# è®­ç»ƒç›¸å…³å‚æ•°
	parser.add_argument('--gpu', type=int, default=1, help='GPU device id')
	parser.add_argument('--epochs', type=int, default=15, help='Maximum number of training epochs')
	parser.add_argument('--batch_size', type=int, default=64, help='Batch size for training')
	parser.add_argument('--lr', type=float, default=0.0002, help='Learning rate')
	parser.add_argument('--l1_lambda', type=float, default=0.01, help='L1 regularization coefficient')
	parser.add_argument('--weight_decay', type=float, default=0.05, help='L2 weight decay')
	parser.add_argument('--patience', type=int, default=5, help='Early stopping patience')
	parser.add_argument('--split_ratio', type=float, default=0.99, help='Train/test split ratio')
	parser.add_argument('--seed', type=int, default=42, help='Random seed')
	parser.add_argument('--seq_length', type=int, default=36, help='Sequence length')
	
	# é²æ£’æ€§æµ‹è¯•å‚æ•°
	parser.add_argument('--noise_levels', nargs='+', type=float, default=[0.05, 0.1],
						help='Noise levels for robustness testing')
	parser.add_argument('--missing_ratio', nargs='+', type=float, default=[0.05, 0.1],
						help='Missing data ratio(s) for robustness testing, e.g. --missing_ratio 0.05 0.1')
	parser.add_argument('--include_seasonal_eval', action='store_true', default=False,
						help='Include seasonal evaluation in default (test_split) mode')
	parser.add_argument('--seasonal_mode', type=str, default='independent', choices=['test_split', 'independent'],
						help='Seasonal analysis mode for baselines')
	parser.add_argument('--season_split_ratio', type=float, default=0.95,
						help='Train split ratio within each season in independent mode')
	
	args = parser.parse_args()
	
	# è®¾ç½®éšæœºç§å­
	seed_everything(seed=args.seed)
	
	# è®¾ç½®è®¾å¤‡
	torch.cuda.set_device(args.gpu)
	device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
	print(f"Using device: {device}")
	
	# åˆ›å»ºç»“æœä¿å­˜ç›®å½•
	script_dir = Path(os.path.dirname(os.path.abspath(__file__)))
	results_dir = script_dir / 'results' / 'baseline_robustness'
	results_dir.mkdir(parents=True, exist_ok=True)
	
	# é€‰æ‹©è¦è¿è¡Œçš„æ¨¡å‹æ¸…å•
	models_to_run = []
	if args.models and len(args.models) > 0:
		models_to_run = args.models
	elif args.model:
		models_to_run = [args.model]
	else:
		print("æœªæŒ‡å®š --model æˆ– --modelsï¼Œé€€å‡ºã€‚")
		return

	print(f"\nğŸ¯ å°†ä¾æ¬¡è¿è¡Œæ¨¡å‹: {', '.join(models_to_run)}")
	print(f"æ•°æ®é›†: {args.dataset}")
	print(f"é¢„æµ‹å°ºåº¦: {args.prediction_scale}")
	print(f"ç»“æœä¿å­˜ç›®å½•: {results_dir}")

	for model_name in models_to_run:
		print(f"\n--- å¼€å§‹è¿è¡Œ {model_name} ---")
		results = run_baseline_robustness_experiment(
			args.dataset, args.prediction_scale, args, device, model_name
		)
		if results is not None:
			save_results(results, results_dir, args.dataset, f"{args.prediction_scale}_{model_name}")
			print(f"âœ… {model_name} å®Œæˆå¹¶å·²ä¿å­˜ç»“æœ")
			# ç®€è¦æ‘˜è¦
			if 'baseline' in results:
				baseline = results['baseline']
				print(f"  åŸºçº¿æ€§èƒ½ - MSE: {baseline['MSE']:.4f}, MAPE: {baseline['MAPE']:.2f}%")
		else:
			print(f"âš ï¸ {model_name} è¿è¡Œå¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªæ¨¡å‹")

if __name__ == '__main__':
	main() 